{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cropping Object frames\n",
    "* The code written is based on methods from [LeagueAI](https://arxiv.org/abs/1905.13546) and the associated [Github repo](https://github.com/Oleffa/LeagueAI)\n",
    "## Methodology\n",
    "1. Removing the unicolor background of the images by modifying the alpha channel(for transparency) of all unicolor pixels.\n",
    "2. Image is cropped.\n",
    "3. Cropped dimensions will serve as bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageFilter\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_in_dir_as_dict(path, filt='.csv'):\n",
    "    ''' Get all files from path. Returns a dict of folder + path'''\n",
    "    assert os.path.exists(path), \"The path {} was not found!\".format(path)\n",
    "    f = dict()\n",
    "    for (dirpath, dirnames, filenames) in os.walk(path):\n",
    "        files = [os.path.join(dirpath,f) for f in filenames if filt in f]\n",
    "        if len(files) > 0:\n",
    "            f[dirpath] = files\n",
    "    return f\n",
    "def get_files_in_dir_as_list(path, filt='.csv'):\n",
    "    f_dict = get_files_in_dir_as_dict(path, filt)\n",
    "    return [k for key in f_dict for k in f_dict[key]]\n",
    "\n",
    "def get_precrop_area(img_size, crop_coeffs = np.array([0.13175231, 0.01315789, 0.84321476, 0.92105263])):\n",
    "    ''' Pre-crop image to some unwanted elements on the screenshot'''\n",
    "    # TEMPLATE_H = 380\n",
    "    # TEMPLATE_W = 759\n",
    "    # h0_coeff = 5/TEMPLATE_H\n",
    "    # h1_coeff = 350/TEMPLATE_H\n",
    "    # w0_coef = 100/TEMPLATE_W\n",
    "    # w1_coeff = 640/TEMPLATE_W\n",
    "    \n",
    "    # crop_coeffs = np.array([0.13175231, 0.01315789, 0.84321476, 0.92105263])\n",
    "    return np.multiply((*img_size, *img_size), crop_coeffs) # (*img_size, *img_size) makes a 1x4 array of w,h,w,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area to pre-crop the images to (min_x, min_y, max_x, max_y), can save runtime for large screenshots with small objects\n",
    "area = (700,300,1240,780)\n",
    "\n",
    "tolerance_offset_1 = 1.0\n",
    "tolerance_offset_2 = 1.0 # Greenscreen: 0.74\n",
    "tolerance_offset_3 = 2.5 # Teemo viewer: 2.5\n",
    "tolerance1 = tolerance_offset_1*25\n",
    "tolerance2 = tolerance_offset_2*25\n",
    "tolerance3 = tolerance_offset_3*25\n",
    "tolerance = (tolerance1,tolerance2,tolerance3)\n",
    "background = (0,255,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgba_channel_equal(c1, c2, tolerance):\n",
    "    return ((abs(int(c1[0]) - int(c2[0])) <= tolerance[0]) and \n",
    "            (abs(int(c1[1]) - int(c2[1])) <= tolerance[1]) and \n",
    "            (abs(int(c1[2]) - int(c2[2])) <= tolerance[2]))\n",
    "\n",
    "def modify_outline(image, thickness):\n",
    "    #image = Image.open(f)\n",
    "    #image = image.convert(\"RGBA\")\n",
    "    \n",
    "    for t in range(thickness):\n",
    "        mask = image.filter(ImageFilter.FIND_EDGES)\n",
    "        mask_data = mask.getdata()\n",
    "        image_data = image.getdata()\n",
    "        w, h = mask_data.size\n",
    "        \n",
    "        out_data=[]\n",
    "        for y in range(0, h):\n",
    "            for x in range(0, w):\n",
    "                index = x + w*y\n",
    "                pixel = (0,0,0,0)\n",
    "                if mask_data[index][3]>0:\n",
    "                    pixel = (255,255,255, 0)\n",
    "                else:\n",
    "                    pixel = (image_data[index][0], image_data[index][1],  image_data[index][2],  image_data[index][3])\n",
    "                out_data.append(pixel)\n",
    "        image.putdata(out_data)\n",
    "    #image.save(out)\n",
    "    return image\n",
    "\n",
    "def get_y_min_max(new_data, w, h, scan_step=5, channel=1, channel_mask=(0,255,0), tolerance=(10,10,10)):\n",
    "    '''Get min max values for y axis. Axis = x'''\n",
    "    min_value = 0\n",
    "    max_value = 0\n",
    "    for y in range(h-1, 0,-scan_step):\n",
    "        for x in range(0, w-1):\n",
    "            data_index = x + w * y\n",
    "            #if abs(new_data[data_index][1] - 255) > 40:\n",
    "            if not rgba_channel_equal(new_data[data_index], channel_mask, tolerance):\n",
    "                #print('max = {}'.format(new_data[data_index][1]))\n",
    "                max_value = y\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "        break\n",
    "        \n",
    "    for y in range(0, h-1, scan_step):\n",
    "        for x in range(0, w-1):\n",
    "            data_index = x + w * y\n",
    "            #if abs(new_data[data_index][1] - 255) > 40: \n",
    "            if not rgba_channel_equal(new_data[data_index], channel_mask, tolerance):\n",
    "                min_value = y\n",
    "                #print('min = {}'.format(new_data[data_index][1]))\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "        break\n",
    "    return min_value-scan_step, max_value+scan_step\n",
    "\n",
    "def get_xy_min_max(tgt_img, scan_step=1, channel=1, channel_mask=(0,255,0), tolerance=(10,10,10)):\n",
    "    # y axis\n",
    "    img_data = tgt_img.getdata()\n",
    "    w,h = tgt_img.size\n",
    "    min_y, max_y = get_y_min_max(img_data,w=w,h=h, \n",
    "                                 channel=channel, \n",
    "                                 channel_mask=channel_mask, \n",
    "                                 tolerance=tolerance,\n",
    "                                scan_step=scan_step)\n",
    "    \n",
    "    # X axis\n",
    "    img = tgt_img.rotate(-90,expand=True)\n",
    "    img_data = img.getdata()\n",
    "    w,h = img.size\n",
    "    min_x,max_x = get_y_min_max(img_data,w=w,h=h, \n",
    "                                 channel=channel, \n",
    "                                 channel_mask=channel_mask, \n",
    "                                 tolerance=tolerance,\n",
    "                                scan_step=scan_step)\n",
    "    \n",
    "    return min_x, min_y, max_x, max_y-scan_step//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_2_cropped_png(input_img_path, background=(0,255,0), tolerance=(10,40,10), \n",
    "                      precrop_bbox= np.array([0.13175231, 0.01315789, 0.84321476, 0.92105263])):\n",
    "    tolerance1, tolerance2, tolerance3 = tolerance\n",
    "    img = Image.open(input_img_path)\n",
    "\n",
    "    # Add alpha channel\n",
    "    img = img.convert(\"RGBA\")\n",
    "    \n",
    "    # Crop initially to remove logo etc\n",
    "    # img = img.crop((100,20,730,420))\n",
    "    crop_bbox = get_precrop_area(img.size, precrop_bbox)\n",
    "    img = img.crop(crop_bbox)\n",
    "    dim = get_xy_min_max(img, channel_mask=background, tolerance=(5,40,5), scan_step=10)\n",
    "    img_cropped = img.crop((dim))\n",
    "    datas = img_cropped.getdata()\n",
    "    newData = list(datas)\n",
    "    \n",
    "    for idx, item in zip(range(len(datas)), datas):\n",
    "        if (abs(item[0] - background[0]) < tolerance1 and \n",
    "         abs(item[1] - background[1]) < tolerance2 and \n",
    "         abs(item[2] - background[2]) < tolerance3): \n",
    "             newData[idx] = (255,255,255,0)\n",
    "        else:\n",
    "            newData[idx] = (item[0], item[1], item[2], 255)\n",
    "            \n",
    "    img_cropped.putdata(newData)\n",
    "    w,h = img_cropped.size\n",
    "    # Crop image to pixel content\n",
    "    dim = get_xy_min_max(img_cropped, channel_mask=background, tolerance=(5,40,5), scan_step=1)\n",
    "    # Save output image as png\n",
    "    img_cropped = img_cropped.crop(dim)\n",
    "    img_cropped = modify_outline(img_cropped, 1)\n",
    "    #img_cropped.save()\n",
    "    return img_cropped\n",
    "\n",
    "def img_2_cropped_png_wrapper(input_img_path, background=(0,255,0),out_path= 'creeps_cropped', source_dir = 'creeps',\n",
    "                             precrop_bbox = np.array([0.13175231, 0.01315789, 0.84321476, 0.92105263])):\n",
    "    img = img_2_cropped_png(input_img_path, background=background, tolerance=tolerance, precrop_bbox=precrop_bbox)\n",
    "    if img == None:\n",
    "        return False\n",
    "    rel_path = os.path.relpath(input_img_path, source_dir)\n",
    "    save_path = os.path.join(out_path, os.path.dirname(rel_path))\n",
    "    #print(save_path)\n",
    "    base_name = os.path.basename(input_img_path)\n",
    "    if(not os.path.exists(save_path)):\n",
    "        os.makedirs(save_path)\n",
    "    #print(save_path)\n",
    "    img.save(os.path.join(save_path,base_name))\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Champion Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dir = 'v2_01_champions_10/'\n",
    "image_paths = get_files_in_dir_as_list(root_dir, 'png')\n",
    "out_path = 'v2_01_champs_cropped' ########################TODO!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4344"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4344/4344 [09:44<00:00,  7.44it/s]\n"
     ]
    }
   ],
   "source": [
    "for img in tqdm(image_paths):\n",
    "    img_2_cropped_png_wrapper(img,out_path=out_path,source_dir=root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop creep images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = (4, 244, 4) # Green screen\n",
    "out_path = 'creeps_cropped/'\n",
    "creep_image_paths = get_files_in_dir_as_list('creeps', 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 9980/9980 [25:46<00:00,  6.45it/s]\n"
     ]
    }
   ],
   "source": [
    "for img in tqdm(creep_image_paths):\n",
    "    img_2_cropped_png_wrapper(input_img_path=img, background=background, out_path=out_path,source_dir=')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Monster Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2536"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background = (4, 244, 4) # Green screen\n",
    "source_dir = 'v2_1_monsters/'\n",
    "monster_image_paths = get_files_in_dir_as_list(source_dir, 'png')\n",
    "out_path = 'v2_1_monsters_cropped/'\n",
    "len(monster_image_paths)\n",
    "\n",
    "# Skip Gromp. Has to be processed seperately\n",
    "monster_image_paths2 = [x for x in monster_image_paths if 'Gromp' not in x]\n",
    "gromp_image_paths = [x for x in monster_image_paths if 'Gromp' in x]\n",
    "len(monster_image_paths2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'monster_image_paths2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-0246919ed9cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonster_image_paths2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mimg_2_cropped_png_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_img_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackground\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbackground\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msource_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'monster_image_paths2' is not defined"
     ]
    }
   ],
   "source": [
    "for img in tqdm(monster_image_paths2):\n",
    "    img_2_cropped_png_wrapper(input_img_path=img, background=background, out_path=out_path,source_dir=source_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:13<00:00,  7.88it/s]\n"
     ]
    }
   ],
   "source": [
    "for img in tqdm(gromp_image_paths):\n",
    "    img_2_cropped_png_wrapper(input_img_path=img, \n",
    "                              background=background, \n",
    "                              out_path=out_path,\n",
    "                              source_dir=source_dir,\n",
    "                             precrop_bbox = np.array([0.13175231, 0.01315789, 0.84321476, 0.60]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'v2_monsters_cropped/'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=80x125 at 0x1B27FE52A00>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_obj.paste()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python38664bit5086e08cf0ac40048632b8a4bca36774"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
