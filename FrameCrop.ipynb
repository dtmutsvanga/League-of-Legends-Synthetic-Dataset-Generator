{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cropping Object frames\n",
    "* The code written is based on methods from [LeagueAI](https://arxiv.org/abs/1905.13546) and the associated [Github repo](https://github.com/Oleffa/LeagueAI)\n",
    "## Methodology\n",
    "1. Removing the unicolor background of the images by modifying the alpha channel(for transparency) of all unicolor pixels.\n",
    "2. Image is cropped.\n",
    "3. Cropped dimensions will serve as bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageFilter\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_in_dir_as_dict(path, filt='.csv'):\n",
    "    ''' Get all files from path. Returns a dict of folder + path'''\n",
    "    assert os.path.exists(path), \"The path {} was not found!\".format(path)\n",
    "    f = dict()\n",
    "    for (dirpath, dirnames, filenames) in os.walk(path):\n",
    "        files = [os.path.join(dirpath,f) for f in filenames if filt in f]\n",
    "        if len(files) > 0:\n",
    "            f[dirpath] = files\n",
    "    return f\n",
    "def get_files_in_dir_as_list(path, filt='.csv'):\n",
    "    f_dict = get_files_in_dir_as_dict(path, filt)\n",
    "    return [k for key in f_dict for k in f_dict[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area to pre-crop the images to (min_x, min_y, max_x, max_y), can save runtime for large screenshots with small objects\n",
    "area = (700,300,1240,780)\n",
    "\n",
    "tolerance_offset_1 = 1.0\n",
    "tolerance_offset_2 = 1.0 # Greenscreen: 0.74\n",
    "tolerance_offset_3 = 2.5 # Teemo viewer: 2.5\n",
    "tolerance1 = tolerance_offset_1*25\n",
    "tolerance2 = tolerance_offset_2*25\n",
    "tolerance3 = tolerance_offset_3*25\n",
    "tolerance = (tolerance1,tolerance2,tolerance3)\n",
    "background = (0,255,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgba_channel_equal(c1, c2, tolerance):\n",
    "    return ((abs(int(c1[0]) - int(c2[0])) <= tolerance[0]) and \n",
    "            (abs(int(c1[1]) - int(c2[1])) <= tolerance[1]) and \n",
    "            (abs(int(c1[2]) - int(c2[2])) <= tolerance[2]))\n",
    "\n",
    "def modify_outline(image, thickness):\n",
    "    #image = Image.open(f)\n",
    "    #image = image.convert(\"RGBA\")\n",
    "    \n",
    "    for t in range(thickness):\n",
    "        mask = image.filter(ImageFilter.FIND_EDGES)\n",
    "        mask_data = mask.getdata()\n",
    "        image_data = image.getdata()\n",
    "        w, h = mask_data.size\n",
    "        \n",
    "        out_data=[]\n",
    "        for y in range(0, h):\n",
    "            for x in range(0, w):\n",
    "                index = x + w*y\n",
    "                pixel = (0,0,0,0)\n",
    "                if mask_data[index][3]>0:\n",
    "                    pixel = (255,255,255, 0)\n",
    "                else:\n",
    "                    pixel = (image_data[index][0], image_data[index][1],  image_data[index][2],  image_data[index][3])\n",
    "                out_data.append(pixel)\n",
    "        image.putdata(out_data)\n",
    "    #image.save(out)\n",
    "    return image\n",
    "\n",
    "def get_y_min_max(new_data, w, h, scan_step=5, channel=1, channel_mask=(0,255,0), tolerance=(10,10,10)):\n",
    "    '''Get min max values for y axis. Axis = x'''\n",
    "    min_value = 0\n",
    "    max_value = 0\n",
    "    for y in range(h-1, 0,-scan_step):\n",
    "        for x in range(0, w-1):\n",
    "            data_index = x + w * y\n",
    "            #if abs(new_data[data_index][1] - 255) > 40:\n",
    "            if not rgba_channel_equal(new_data[data_index], channel_mask, tolerance):\n",
    "                #print('max = {}'.format(new_data[data_index][1]))\n",
    "                max_value = y\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "        break\n",
    "        \n",
    "    for y in range(0, h-1, scan_step):\n",
    "        for x in range(0, w-1):\n",
    "            data_index = x + w * y\n",
    "            #if abs(new_data[data_index][1] - 255) > 40: \n",
    "            if not rgba_channel_equal(new_data[data_index], channel_mask, tolerance):\n",
    "                min_value = y\n",
    "                #print('min = {}'.format(new_data[data_index][1]))\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "        break\n",
    "    return min_value-scan_step, max_value+scan_step\n",
    "\n",
    "def get_xy_min_max(tgt_img, scan_step=1, channel=1, channel_mask=(0,255,0), tolerance=(10,10,10)):\n",
    "    # y axis\n",
    "    img_data = tgt_img.getdata()\n",
    "    w,h = tgt_img.size\n",
    "    min_y, max_y = get_y_min_max(img_data,w=w,h=h, \n",
    "                                 channel=channel, \n",
    "                                 channel_mask=channel_mask, \n",
    "                                 tolerance=tolerance,\n",
    "                                scan_step=scan_step)\n",
    "    \n",
    "    # X axis\n",
    "    img = tgt_img.rotate(-90,expand=True)\n",
    "    img_data = img.getdata()\n",
    "    w,h = img.size\n",
    "    min_x,max_x = get_y_min_max(img_data,w=w,h=h, \n",
    "                                 channel=channel, \n",
    "                                 channel_mask=channel_mask, \n",
    "                                 tolerance=tolerance,\n",
    "                                scan_step=scan_step)\n",
    "    \n",
    "    return min_x, min_y, max_x, max_y-scan_step//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_2_cropped_png(input_img_path, background=(0,255,0), tolerance=(10,40,10) ):\n",
    "    tolerance1, tolerance2, tolerance3 = tolerance\n",
    "    img = Image.open(input_img_path)\n",
    "    # Add alpha channel\n",
    "    img = img.convert(\"RGBA\")\n",
    "    img = img.crop((100,10,800,400))\n",
    "    dim = get_xy_min_max(img, channel_mask=background, tolerance=(5,40,5), scan_step=10)\n",
    "    img_cropped = img.crop((dim))\n",
    "    datas = img_cropped.getdata()\n",
    "    newData = list(datas)\n",
    "    \n",
    "    for idx, item in zip(range(len(datas)), datas):\n",
    "        if (abs(item[0] - background[0]) < tolerance1 and \n",
    "         abs(item[1] - background[1]) < tolerance2 and \n",
    "         abs(item[2] - background[2]) < tolerance3): \n",
    "             newData[idx] = (255,255,255,0)\n",
    "        else:\n",
    "            newData[idx] = (item[0], item[1], item[2], 255)\n",
    "            \n",
    "    img_cropped.putdata(newData)\n",
    "    w,h = img_cropped.size\n",
    "    # Crop image to pixel content\n",
    "    dim = get_xy_min_max(img_cropped, channel_mask=background, tolerance=(5,40,5), scan_step=1)\n",
    "    # Save output image as png\n",
    "    img_cropped = img_cropped.crop(dim)\n",
    "    img_cropped = modify_outline(img_cropped, 1)\n",
    "    #img_cropped.save()\n",
    "    return img_cropped\n",
    "\n",
    "def img_2_cropped_png_wrapper(input_img_path, background=(0,255,0),out_path= 'D:/SK MSc/II/LoL_Object_Detection/creeps_cropped', root_dir = 'D:/SK MSc/II/LoL_Object_Detection/creeps'):\n",
    "    img = img_2_cropped_png(input_img_path, background=background, tolerance=tolerance)\n",
    "    rel_path = os.path.relpath(input_img_path, root_dir)\n",
    "    save_path = os.path.join(out_path, os.path.dirname(rel_path))\n",
    "    #print(save_path)\n",
    "    base_name = os.path.basename(input_img_path)\n",
    "    if(not os.path.exists(save_path)):\n",
    "        os.makedirs(save_path)\n",
    "    #print(save_path)\n",
    "    img.save(os.path.join(save_path,base_name))\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Champion Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dir = 'champions'\n",
    "image_paths = get_files_in_dir_as_list('champions/', 'png')\n",
    "out_path = 'D:/SK MSc/II/LoL_Object_Detection/chapions_cropped2' ########################TODO!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " rel_path = os.path.relpath(input_img_path, root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10472"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 10472/10472 [31:44<00:00,  5.50it/s]\n"
     ]
    }
   ],
   "source": [
    "for img in tqdm(image_paths):\n",
    "    img_2_cropped_png_wrapper(img,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop creep images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = (4, 244, 4) # Green screen\n",
    "out_path = 'D:/SK MSc/II/LoL_Object_Detection/creeps_cropped/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/SK MSc/II/LoL_Object_Detection/creeps_cropped/'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "creep_image_paths = get_files_in_dir_as_list('D:/SK MSc/II/LoL_Object_Detection/creeps', 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 9980/9980 [25:46<00:00,  6.45it/s]\n"
     ]
    }
   ],
   "source": [
    "for img in tqdm(creep_image_paths):\n",
    "    img_2_cropped_png_wrapper(input_img_path=img, background=background, out_path=out_path,root_dir='D:/SK MSc/II/LoL_Object_Detection/creeps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python38664bit5086e08cf0ac40048632b8a4bca36774"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
